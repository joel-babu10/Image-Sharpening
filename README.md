# Image Sharpening using Knowledge Distillation

A lightweight, real-time image sharpening system designed for video conferencing scenarios. This project leverages a **Teacher-Student knowledge distillation framework** to transfer knowledge from a high-performing deep model (Restormer) to an efficient student model capable of operating at 30‚Äì60 FPS on 1080p images.

---

## üîç Project Summary

- **Goal:** Improve visual clarity in video streams suffering from blurriness caused by compression, noise, or low bandwidth.
- **Approach:** Use a deep Restormer-based Teacher model to train a lightweight Student model via knowledge distillation.
- **Output:** A sharp image or video frame with enhanced structural and perceptual quality.

---

## üìê Architecture

      +---------------------+
      |   Teacher Model     |
      |   (Restormer)       |
      +---------------------+
                ‚Üì
    Feature & Perceptual Loss
                ‚Üì
      +---------------------+
      |   Student Model     |
      |  (UNet/ResUNetLite) |
      +---------------------+
                ‚Üì
     Reconstructed Sharp Image
     
---

## üì¶ Features

- ‚úÖ Deep teacher model (Restormer or ResUNet)
- ‚úÖ Lightweight real-time student model
- ‚úÖ Multi-loss training: MSE, Perceptual, Edge, and Distillation loss
- ‚úÖ Supports high-resolution images (1920√ó1080)
- ‚úÖ Real-time video frame enhancement (30‚Äì60 FPS)
- ‚úÖ Clean training/inference pipeline

---
## üß∞ Model & System Configuration

| Component        | Description                          |
|------------------|--------------------------------------|
| üß† Teacher Model | Restormer                            |
| üß† Student Model | ResUNetLite (KD trained)       |
| üñ•Ô∏è Device         | NVIDIA GPU ( RTX 3050)          |
| üß™ Framework      | PyTorch 2.0, torchvision, OpenCV     |
| üñºÔ∏è Resolution     | 1920√ó1080 (default), supports others |
| üíæ RAM            | 16 GB (minimum recommended)          |
| üßÆ OS             | Windows 10 / Ubuntu 20+              |

## üõ†Ô∏è Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/joel-babu10/image-sharpening-kd.git
cd image-sharpening-kd
pip install -r requirements.txt



## üß™ Training

### 1. Train the Teacher Model (Restormer or ResUNet)

```bash
python train_teacher.py
```

### 2. Train the Student Model with Knowledge Distillation

```bash
python  train_student.py
```

> üí° Make sure `checkpoints/teacher_model.pth` is available before training the student.

---

## üé• Inference on Video

```bash
python video_sharpen.py --input data/input_video.mp4 --output results/output_video.mp4
```

---

## üìÅ Directory Structure

```
.
‚îú‚îÄ‚îÄ checkpoints/         # Saved model weights (*.pth)
‚îú‚îÄ‚îÄ data/                # Input/output image or video files
‚îú‚îÄ‚îÄ models/              # Teacher and student model definitions
‚îú‚îÄ‚îÄ results/             # Output sharpened images/videos
‚îú‚îÄ‚îÄ utils/               # Loss functions, metrics, etc.
‚îú‚îÄ‚îÄ main.py              # Training script
‚îú‚îÄ‚îÄ video_sharpen.py     # Inference script
‚îú‚îÄ‚îÄ requirements.txt     # Project dependencies
‚îî‚îÄ‚îÄ README.md            # Project overview
```

---

## üìä Evaluation Metrics

| Model         | SSIM  | PSNR | FPS    |
|---------------|-------|------|--------|
| Teacher       | 0.9605 | 29.5 | 10‚Äì12  |
| Student (KD)  | 0.9459 | 28.3 | 35‚Äì60  |

- **SSIM (Structural Similarity):** Higher is better  
- **PSNR (Peak Signal-to-Noise Ratio):** Higher is better  
- **FPS (Frames Per Second):** Measured on 1080p input  

**MOS (Mean Opinion Score):** 4.4 / 5 (from subjective evaluation)

---

## üìà Example Outputs

![Student Output](results//teacher_student_comparison/comparison_004.png)


> Replace the placeholders with your real outputs stored in the `results/` folder.

---

## üë• Authors

- **Joel Babu** ‚Äî Model training, architecture, experiments  
- **Hridya R Kurup** ‚Äî Loss functions, evaluation metrics  
- **Irene Anna Oommen** ‚Äî Inference pipeline and optimization

---

## üßæ Step-by-Step Guide

This section outlines how to go from setup to results, even if you're new to machine learning.

### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/joel-babu10/image-sharpening-kd.git
cd image-sharpening-kd
```

### 2Ô∏è‚É£ Install Required Libraries

Make sure Python 3.8+ is installed, then run:

```bash
pip install -r requirements.txt
```

> Optionally, use a virtual environment for isolation: `python -m venv venv && source venv/bin/activate`

---

### 3Ô∏è‚É£ Prepare the Dataset

You can use your own high-quality images or public datasets. The folder structure should look like this:

```
data/
‚îú‚îÄ‚îÄ high_res/        # High-quality ground truth images
‚îî‚îÄ‚îÄ degraded/        # Blurred versions of the originals (use bicubic/bilinear resize to generate)
```

To generate blurred images:

```python
# Example using OpenCV (in a custom script or notebook)
import cv2
img = cv2.imread("data/original/0001.png")
degraded = cv2.resize(cv2.resize(img, (img.shape[1]//2, img.shape[0]//2)), (img.shape[1], img.shape[0]))
cv2.imwrite("data/degraded/0001.png", degraded)
```

Make sure both folders contain corresponding image names like `0001.png`, `0002.png`, etc.

---

### 4Ô∏è‚É£ Train the Teacher Model

This will take time and computational power (GPU recommended).

```bash
python train_teacher.py
```

After training, you‚Äôll get a model saved in:

```
checkpoints/teacher_model.pth
```

---

### 5Ô∏è‚É£ Train the Student Model

This uses the trained teacher weights for knowledge distillation.

```bash
python train_student.py
```

You should now have:

```
checkpoints/student_model.pth
```

---

### 6Ô∏è‚É£ Test on an Image (Optional)

```bash
python test_student.py
```
```

python test_teacher.py
```

---

### 7Ô∏è‚É£ Test on a Video

To sharpen a blurry video (MP4):

```bash
python video_sharpen.py --input data/input_video.mp4 --output results/output_video.mp4
```

The sharpened video will be saved in `results/`.

---

### ‚úÖ Tips for Best Results

- Use consistent image dimensions (e.g., 512√ó512 or 1080p) for training
- Normalize images to [0, 1] if modifying dataset pipeline
- Use GPU for faster training (`torch.device('cuda')`)
- If model outputs are white/black, check activation (use `sigmoid` or clamp output)

---




## üôã Contributing

We welcome contributions! Feel free to fork, improve performance, or expand support to mobile/webcam use cases.
