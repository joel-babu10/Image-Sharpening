# Image Sharpening using Knowledge Distillation

A lightweight, real-time image sharpening system designed for video conferencing scenarios. This project leverages a **Teacher-Student knowledge distillation framework** to transfer knowledge from a high-performing deep model (Restormer) to an efficient student model capable of operating at 30â€“60 FPS on 1080p images.

---

## ðŸ” Project Summary

- **Goal:** Improve visual clarity in video streams suffering from blurriness caused by compression, noise, or low bandwidth.
- **Approach:** Use a deep Restormer-based Teacher model to train a lightweight Student model via knowledge distillation.
- **Output:** A sharp image or video frame with enhanced structural and perceptual quality.

---

## ðŸ“ Architecture

      +---------------------+
      |   Teacher Model     |
      |   (Restormer)       |
      +---------------------+
                â†“
    Feature & Perceptual Loss
                â†“
      +---------------------+
      |   Student Model     |
      |  (UNet/ResUNetLite) |
      +---------------------+
                â†“
     Reconstructed Sharp Image
     
---

## ðŸ“¦ Features

- âœ… Deep teacher model (Restormer or ResUNet)
- âœ… Lightweight real-time student model
- âœ… Multi-loss training: MSE, Perceptual, Edge, and Distillation loss
- âœ… Supports high-resolution images (1920Ã—1080)
- âœ… Real-time video frame enhancement (30â€“60 FPS)
- âœ… Clean training/inference pipeline

---

## ðŸ› ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/joel-babu10/image-sharpening-kd.git
cd image-sharpening-kd
pip install -r requirements.txt



## ðŸ§ª Training

### 1. Train the Teacher Model (Restormer or ResUNet)

```bash
python train_teacher.py
```

### 2. Train the Student Model with Knowledge Distillation

```bash
python  train_student.py
```

> ðŸ’¡ Make sure `checkpoints/teacher_model.pth` is available before training the student.

---

## ðŸŽ¥ Inference on Video

```bash
python video_sharpen.py --input data/input_video.mp4 --output results/output_video.mp4
```

---

## ðŸ“ Directory Structure

```
.
â”œâ”€â”€ checkpoints/         # Saved model weights (*.pth)
â”œâ”€â”€ data/                # Input/output image or video files
â”œâ”€â”€ models/              # Teacher and student model definitions
â”œâ”€â”€ results/             # Output sharpened images/videos
â”œâ”€â”€ utils/               # Loss functions, metrics, etc.
â”œâ”€â”€ main.py              # Training script
â”œâ”€â”€ video_sharpen.py     # Inference script
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ README.md            # Project overview
```

---

## ðŸ“Š Evaluation Metrics

| Model         | SSIM  | PSNR | FPS    |
|---------------|-------|------|--------|
| Teacher       | 0.9605 | 29.5 | 10â€“12  |
| Student (KD)  | 0.9459 | 28.3 | 35â€“60  |

- **SSIM (Structural Similarity):** Higher is better  
- **PSNR (Peak Signal-to-Noise Ratio):** Higher is better  
- **FPS (Frames Per Second):** Measured on 1080p input  

**MOS (Mean Opinion Score):** 4.4 / 5 (from subjective evaluation)

---

## ðŸ“ˆ Example Outputs

![Student Output](results//teacher_student_comparison/comparison_004.png)


> Replace the placeholders with your real outputs stored in the `results/` folder.

---

## ðŸ‘¥ Authors

- **Joel Babu** â€” Model training, architecture, experiments  
- **Hridya R Kurup1** â€” Loss functions, evaluation metrics  
- **Irene Anna Oommen 2** â€” Inference pipeline and optimization

---

## ðŸ“„ License

This project is released under the [MIT License](LICENSE).

---

## ðŸ™‹ Contributing

We welcome contributions! Feel free to fork, improve performance, or expand support to mobile/webcam use cases.
